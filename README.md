# LoRA_Project1
Fine-tune LLM model- LoRA/ QLoRA

This repository contains the MedicalQA model fine-tuned on medical question-answering data and deployed on Modal for inference.
 
 # About the Project:
 
MedicalQA is an AI-powered question-answering model fine-tuned to predict medical diagnoses based on patient symptoms. The model is deployed on Modal, allowing for cloud-based inference.

Model Used: Meta-Llama-3.1-8B
Frameworks: Hugging Face Transformers, PyTorch, Modal

 # Features

 Fine-tuned LLM for medical question answering
 Deployed on Modal for fast, scalable inference
 Uses Hugging Face API for secure model access
 Lightweight & Optimized using LoRA training
 Simple API Interface for querying the model
